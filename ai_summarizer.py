import openai
from datetime import datetime, timedelta
import json
import re
from collections import defaultdict
from config import Config

class AISummarizer:
    def __init__(self):
        self.config = Config()
        if self.config.OPENAI_API_KEY:
            openai.api_key = self.config.OPENAI_API_KEY
        else:
            print("è­¦å‘Š: æœªè®¾ç½®OpenAI APIå¯†é’¥ï¼Œå°†æ— æ³•ä½¿ç”¨AIæ€»ç»“åŠŸèƒ½")
    
    def group_articles_by_month(self, articles):
        """æŒ‰æœˆä»½åˆ†ç»„æ–‡ç« """
        monthly_articles = defaultdict(list)
        
        for article in articles:
            # è§£æå‘å¸ƒæ—¶é—´
            publish_date = self._parse_date(article.get('publish_time', ''))
            if publish_date:
                month_key = publish_date.strftime('%Y-%m')
                monthly_articles[month_key].append(article)
        
        return dict(monthly_articles)
    
    def _parse_date(self, date_str):
        """è§£æå„ç§æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²"""
        if not date_str:
            return None
            
        # å¸¸è§çš„CSDNæ—¥æœŸæ ¼å¼
        date_patterns = [
            r'(\d{4})-(\d{1,2})-(\d{1,2})',  # 2025-09-15
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',  # 2025å¹´9æœˆ15æ—¥
            r'(\d{1,2})-(\d{1,2})',  # 09-15 (å½“å¹´)
            r'(\d{1,2})æœˆ(\d{1,2})æ—¥',  # 9æœˆ15æ—¥ (å½“å¹´)
        ]
        
        current_year = datetime.now().year
        
        for pattern in date_patterns:
            match = re.search(pattern, date_str)
            if match:
                try:
                    groups = match.groups()
                    if len(groups) == 3:  # å¹´æœˆæ—¥
                        year, month, day = map(int, groups)
                    elif len(groups) == 2:  # æœˆæ—¥
                        year = current_year
                        month, day = map(int, groups)
                    else:
                        continue
                    
                    return datetime(year, month, day)
                except ValueError:
                    continue
        
        return None
    
    def generate_monthly_summary(self, articles, month_key):
        """ä¸ºæŒ‡å®šæœˆä»½ç”ŸæˆAIæ€»ç»“"""
        if not self.config.OPENAI_API_KEY:
            return self._generate_simple_summary(articles, month_key)
        
        # å‡†å¤‡æ–‡ç« å†…å®¹
        articles_text = self._prepare_articles_for_summary(articles)
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹{month_key}æœˆä»½çš„CSDNåšå®¢æ–‡ç« ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æœˆåº¦æ€»ç»“æŠ¥å‘Šã€‚

æ–‡ç« å†…å®¹ï¼š
{articles_text}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼ç”Ÿæˆæ€»ç»“ï¼š

## {month_key} æœˆåº¦åšå®¢æ€»ç»“

### ğŸ“Š åŸºæœ¬ç»Ÿè®¡
- å‘å¸ƒæ–‡ç« æ•°é‡ï¼š{len(articles)}ç¯‡
- ä¸»è¦æŠ€æœ¯é¢†åŸŸï¼š[è¯·åˆ†ææ–‡ç« æ¶‰åŠçš„æŠ€æœ¯é¢†åŸŸ]
- æ€»é˜…è¯»é‡ï¼š[è®¡ç®—æ€»é˜…è¯»é‡]
- æ€»ç‚¹èµæ•°ï¼š[è®¡ç®—æ€»ç‚¹èµæ•°]

### ğŸ¯ æ ¸å¿ƒä¸»é¢˜åˆ†æ
[è¯·åˆ†ææœ¬æœˆæ–‡ç« çš„ä¸»è¦æŠ€æœ¯ä¸»é¢˜å’Œæ–¹å‘]

### ğŸ’¡ æŠ€æœ¯äº®ç‚¹
[è¯·æå–æœ¬æœˆæœ€æœ‰ä»·å€¼çš„æŠ€æœ¯å†…å®¹å’Œè§è§£]

### ğŸ“ˆ æˆé•¿æ”¶è·
[è¯·åˆ†ææœ¬æœˆåœ¨æŠ€æœ¯å­¦ä¹ å’Œåˆ†äº«æ–¹é¢çš„æˆé•¿]

### ğŸ”¥ çƒ­é—¨æ–‡ç« 
[è¯·åˆ—å‡ºé˜…è¯»é‡æˆ–ç‚¹èµæ•°è¾ƒé«˜çš„æ–‡ç« ]

### ğŸš€ ä¸‹æœˆå±•æœ›
[åŸºäºæœ¬æœˆå†…å®¹ï¼Œå»ºè®®ä¸‹æœˆå¯ä»¥å…³æ³¨çš„æŠ€æœ¯æ–¹å‘]

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå†…å®¹è¦ä¸“ä¸šä¸”æœ‰æ·±åº¦ã€‚
"""

        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åšå®¢åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†ææŠ€æœ¯æ–‡ç« å¹¶ç”Ÿæˆæ·±åº¦æ€»ç»“ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"AIæ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_simple_summary(articles, month_key)
    
    def _prepare_articles_for_summary(self, articles):
        """å‡†å¤‡æ–‡ç« å†…å®¹ç”¨äºAIæ€»ç»“"""
        articles_text = ""
        
        for i, article in enumerate(articles, 1):
            title = article.get('title', 'æ— æ ‡é¢˜')
            content = article.get('content', '')[:500]  # é™åˆ¶é•¿åº¦
            read_count = article.get('read_count', 0)
            like_count = article.get('like_count', 0)
            
            articles_text += f"""
{i}. æ ‡é¢˜ï¼š{title}
   é˜…è¯»é‡ï¼š{read_count} | ç‚¹èµæ•°ï¼š{like_count}
   å†…å®¹æ‘˜è¦ï¼š{content}...
   
"""
        
        return articles_text
    
    def _generate_simple_summary(self, articles, month_key):
        """ç”Ÿæˆç®€å•çš„ç»Ÿè®¡æ€»ç»“ï¼ˆä¸ä½¿ç”¨AIï¼‰"""
        total_reads = sum(article.get('read_count', 0) for article in articles)
        total_likes = sum(article.get('like_count', 0) for article in articles)
        total_comments = sum(article.get('comment_count', 0) for article in articles)
        
        # æå–å…³é”®è¯
        all_titles = ' '.join(article.get('title', '') for article in articles)
        keywords = self._extract_keywords(all_titles)
        
        # æ‰¾å‡ºçƒ­é—¨æ–‡ç« 
        hot_articles = sorted(articles, 
                            key=lambda x: x.get('read_count', 0) + x.get('like_count', 0) * 5, 
                            reverse=True)[:3]
        
        summary = f"""## {month_key} æœˆåº¦åšå®¢æ€»ç»“

### ğŸ“Š åŸºæœ¬ç»Ÿè®¡
- å‘å¸ƒæ–‡ç« æ•°é‡ï¼š{len(articles)}ç¯‡
- æ€»é˜…è¯»é‡ï¼š{total_reads}
- æ€»ç‚¹èµæ•°ï¼š{total_likes}
- æ€»è¯„è®ºæ•°ï¼š{total_comments}

### ğŸ¯ ä¸»è¦å…³é”®è¯
{', '.join(keywords[:10])}

### ğŸ”¥ çƒ­é—¨æ–‡ç« 
"""
        
        for i, article in enumerate(hot_articles, 1):
            title = article.get('title', 'æ— æ ‡é¢˜')
            reads = article.get('read_count', 0)
            likes = article.get('like_count', 0)
            summary += f"{i}. {title} (é˜…è¯»:{reads}, ç‚¹èµ:{likes})\n"
        
        return summary
    
    def _extract_keywords(self, text):
        """ç®€å•çš„å…³é”®è¯æå–"""
        # æŠ€æœ¯ç›¸å…³å…³é”®è¯
        tech_keywords = [
            'Python', 'Java', 'JavaScript', 'C++', 'Go', 'Rust',
            'React', 'Vue', 'Angular', 'Node.js', 'Django', 'Flask',
            'MySQL', 'Redis', 'MongoDB', 'PostgreSQL',
            'Docker', 'Kubernetes', 'Linux', 'Git',
            'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ',
            'ç®—æ³•', 'æ•°æ®ç»“æ„', 'è®¾è®¡æ¨¡å¼',
            'å‰ç«¯', 'åç«¯', 'å…¨æ ˆ', 'å¾®æœåŠ¡',
            'äº‘è®¡ç®—', 'å¤§æ•°æ®', 'åŒºå—é“¾'
        ]
        
        found_keywords = []
        text_upper = text.upper()
        
        for keyword in tech_keywords:
            if keyword.upper() in text_upper or keyword in text:
                found_keywords.append(keyword)
        
        return found_keywords
    
    def generate_all_monthly_summaries(self, articles):
        """ç”Ÿæˆæ‰€æœ‰æœˆä»½çš„æ€»ç»“"""
        monthly_articles = self.group_articles_by_month(articles)
        summaries = {}
        
        for month_key, month_articles in monthly_articles.items():
            print(f"æ­£åœ¨ç”Ÿæˆ{month_key}æœˆä»½æ€»ç»“...")
            summary = self.generate_monthly_summary(month_articles, month_key)
            summaries[month_key] = {
                'summary': summary,
                'article_count': len(month_articles),
                'articles': month_articles
            }
        
        return summaries

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    summarizer = AISummarizer()
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®
    try:
        with open('articles.json', 'r', encoding='utf-8') as f:
            articles = json.load(f)
        
        summaries = summarizer.generate_all_monthly_summaries(articles)
        
        # ä¿å­˜æ€»ç»“
        with open('monthly_summaries.json', 'w', encoding='utf-8') as f:
            json.dump(summaries, f, ensure_ascii=False, indent=2)
        
        print("æœˆåº¦æ€»ç»“ç”Ÿæˆå®Œæˆï¼")
        
    except FileNotFoundError:
        print("æœªæ‰¾åˆ°articles.jsonæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«è·å–æ–‡ç« æ•°æ®")
